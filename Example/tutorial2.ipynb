{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tutorial2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPTyO1ik9IJgSygTsmJnXiN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oxanaRC/CE888/blob/master/Example/tutorial2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bmNYRSo4Vyz",
        "colab_type": "text"
      },
      "source": [
        "From tutorial **How to Develop a CNN for MNIST Handwritten Digit Classification** https://machinelearningmastery.com/how-to-develop-a-convolutional-neural-network-from-scratch-for-mnist-handwritten-digit-classification/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBlsX7kT4yWx",
        "colab_type": "text"
      },
      "source": [
        "The MNIST dataset is an acronym that stands for the Modified National Institute of Standards and Technology dataset.\n",
        "\n",
        "It is a dataset of 60,000 small square 28×28 pixel grayscale images of handwritten single digits between 0 and 9.\n",
        "\n",
        "The task is to classify a given image of a handwritten digit into one of 10 classes representing integer values from 0 to 9, inclusively.\n",
        "\n",
        "It is a widely used and deeply understood dataset and, for the most part, is “solved.” Top-performing models are deep learning convolutional neural networks that achieve a classification accuracy of above 99%, with an error rate between 0.4 %and 0.2% on the hold out test dataset.\n",
        "\n",
        "The example below loads the MNIST dataset using the Keras API and creates a plot of the first nine images in the training dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zt_KY7Sk42wQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "outputId": "905cb077-c8b6-4486-9bdf-507855a9b51a"
      },
      "source": [
        "\n",
        "# example of loading the mnist dataset\n",
        "from keras.datasets import mnist\n",
        "from matplotlib import pyplot\n",
        "# load dataset\n",
        "(trainX, trainy), (testX, testy) = mnist.load_data()\n",
        "# summarize loaded dataset\n",
        "print('Train: X=%s, y=%s' % (trainX.shape, trainy.shape))\n",
        "print('Test: X=%s, y=%s' % (testX.shape, testy.shape))\n",
        "# plot first few images\n",
        "for i in range(9):\n",
        "\t# define subplot\n",
        "\tpyplot.subplot(330 + 1 + i)\n",
        "\t# plot raw pixel data\n",
        "\tpyplot.imshow(trainX[i], cmap=pyplot.get_cmap('gray'))\n",
        "# show the figure\n",
        "pyplot.show()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 1s 0us/step\n",
            "Train: X=(60000, 28, 28), y=(60000,)\n",
            "Test: X=(10000, 28, 28), y=(10000,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAU4AAAD7CAYAAAAFI30bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deZAU9fnH8fcjUUQRBTWIeIAnouKt\nqBSSCB6I4hFRAirGiOWNpcYr8afx1sQK3qIiqFTQBAU0EiQK4oEGNKQih4JGFAXxBlEh6Pf3x863\np4fd2Z3eneme7v28qra2p7tn+2Ge3ebp7u9hzjlERKR06yQdgIhI2ujEKSISkU6cIiIR6cQpIhKR\nTpwiIhHpxCkiElGTTpxmdoSZvW1mC83s8nIFJclSXrNLuS0Pa2w7TjNrAbwD9AEWAzOBgc65ueUL\nT+KmvGaXcls+P2nCe/cHFjrn3gMws7FAf6BoEsysube2/8w5t3nSQTRAeY0uDXmFiLlVXovntSmX\n6h2BD0OvF+fWSXGLkg6gBMprdGnIKyi3URXNa1MqzpKY2VBgaKWPI/FSXrNJeS1NU06cHwFbh15v\nlVtXwDk3AhgBKv1TQnnNrgZzq7yWpimX6jOBHc2ss5mtB5wMTCxPWJIg5TW7lNsyaXTF6ZxbY2bn\nAZOBFsBI59ycskUmiVBes0u5LZ9GN0dq1MFU+r/hnNs36SDKTXlVXjOqaF7Vc0hEJCKdOEVEIqp4\ncySRuOyzzz7B8nnnnQfAqaeeCsAjjzwCwJ133hns8+abb8YYnWSJKk4RkYgy+3CoRYsWwfLGG29c\ndD9fmWywwQYA7LzzzgCce+65wT5/+MMfABg4cCAA33//fbDt5ptvBuDaa68tJSw9RKiAPffcE4AX\nXnghWNemTZs69/3666+D5U033bRcISivVeTQQw8FYMyYMQAccsghwba33347yo/SwyERkXLRiVNE\nJKJUPhzaZpttguX11lsPgIMOOgiAHj16ALDJJpsE+5xwwgkl/+zFixcDcMcddwTrjjvuOABWrFgB\nwL///e9g24svvhgpdimf/fffH4Bx48YBhbdk/C0on7PVq1cDhZfn3bt3B/IPifw+UrqePXsChZ/r\nU089lVQ4AOy3334AzJw5s2LHUMUpIhJRqirOuh4C1PfgJ4off/wRgN/+9rcAfPPNN8E2f5N5yZIl\nAHz55ZfBtog3m6WR/MO7vffeO1j32GOPAdChQ4ei71uwYAEAt956KwBjx44Ntr3yyitAPuc33XRT\nGSNuHnr16gXAjjvuGKxLouJcZ518Ddi5c2cAtt12WwDMrPzHK/tPFBHJuFRVnB988AEAn3/+ebAu\nSsX5+uuvA/DVV18F6372s58B+ftbjz76aJPjlPK7//77gXyTsFL5CrV169ZA4T1pXy1169atDBE2\nT76DwYwZMxKNI3zVceaZZwL5K5L58+eX/XiqOEVEItKJU0QkogYv1c1sJNAPWOac2y23rh3wONAJ\neB8Y4Jz7stjPKJcvvvgCgEsvvTRY169fPwD+9a9/AYXNiLzZs2cD0KdPHwBWrlwZbNt1110BuPDC\nCysQcfWqprzWx/c/P+qoo4C6b/T7y++nn346WOd7e3388cdA/vcj/GDv5z//edGfmWZx5jb8UCZJ\nDz74YK11/sFgJZTyrx4FHLHWusuB551zOwLP515LuoxCec2qUSi3FdVgxemcm25mndZa3R/olVse\nDUwDLitjXPUaP358sOybJvmGznvssQcAZ5xxRrCPrz7ClaY3Z07NANhDhzav+amqMa9hvunZlClT\ngHzf8/DYCpMmTQLyD4zCfZJ9EyNfiXz66adAYecF3wTNV7Phpk5pHjkpjtz6B2rt27dv7I8oq7oe\nEvvfnUpo7FP19s65JbnlpUDRT0+z5qWK8ppdJeVWeS1Nk5sjOedcfaOoVHrWvOXLlxe8Do9+4/nm\nCY8//jiQrzSkuCTyutNOOwXL/j62ryQ+++wzIN8JAWD06NFAvrPC3/72t2BbeLkhrVq1AuDiiy8O\n1g0aNChS7GlSX25LzWvfvn2B/GeXFF/x+kbvYR99VGty1rJp7J3dT8ysA0Du+7LyhSQJUl6zS7kt\no8ZWnBOB04Cbc98nlC2iJrrmmmuAwtHA/b2v3r17A/Dcc8/FHldKJJLXli1bAvl70ZCvaPy9a9/Q\netasWcE+5a52woPHZFBZc+vHrfX8s4K4+d+Z8L3Wd955B8j/7lRCgxWnmf0ZmAHsbGaLzewMaj78\nPma2AOidey0porxml3JbeaU8VS/Wx+3QMsciMVJes0u5rbxU9VUvhW9y5B8IQb5pyQMPPADA1KlT\ng23+0u/uu+8GCpu7SDz22msvIH95Hta/f39A455Wu0qOfRmeBuWII2qapw4ePBiAww47rNb+1113\nHVA4JkW5VUezfxGRFMlcxem9++67wfKQIUMAePjhhwE45ZRTgm1+ecMNNwTy08iGm71IZd1+++1A\nYddHX2FWstL03QXVPK3p2rVrV9J+voOKz7V/YLvVVlsF+/hZHXyTsHC3zu+++w7Ij3S2atUqAH7y\nk/yp7I033oj+D4hIFaeISESZrTjD/IjUvtO/r3AgP5XojTfeCORHjb7hhhuCfSrZkLY58wO0+O6V\n4fvLEydOrPjxfaXpj+sHg5GG+crPf3b33XdfsO3KK68s+j7fVdNXnGvWrAHg22+/DfaZO3cuACNH\njgQKm6D5K5BPPvkEyM8RFm6aVonxN9emilNEJCKdOEVEImoWl+reW2+9BcCAAQOCdUcffTSQf3B0\n1llnAYWTT/lxPKW8/OWVfxiwbFm+F6AfV6BcfO8k37MszI+wdcUVV5T1mFl2zjnnALBo0SIgPz13\nQ/z0N36Es3nz5gHw2muvRTq+H81s8803B+C9996L9P6mUsUpIhJRs6o4vXDDWD85mx+30Tdr6Nmz\nZ7CPn9Rr2rRp8QTYTPmmJVC+5mC+0vTjc4ZnD/APFv74xz8ChVNCS2luueWWRI7rH+p648aNi/X4\nqjhFRCJqVhWnbwrxi1/8Ili33377AYUNaCHfJAJg+vTpMUQn5WyC5Js4+QrzpJNOAmDChPygQCec\ncELZjifJ8k0O46KKU0QkosxWnOHxAs877zwAjj/+eAC22GKLou/74YcfgMJ7bOqSVxm+EbT/fuyx\nxwbbGjPr6EUXXRQs/+53vwPyI8iPGTMGyI/rKdIUpYzHubWZTTWzuWY2x8wuzK1vZ2ZTzGxB7nvb\nyocr5aK8ZpPyGo9SLtXXABc757oC3YFzzawrmm407ZTXbFJeY1DKQMZLgCW55RVmNg/oSBVNJQv5\ny28/Vay/PAfo1KlTg+/3/WF9H/U4+konqRry6vs5++/hWyh33HEHkO+v/PnnnwPQvXv3YB8/spUf\ncSc8wo5vaD158mQA7rnnnvL/A6pQNeQ1Tv42T3iiv6iN6Rsj0j3O3FzNewGvo+lGM0N5zSbltXJK\nPnGaWWtgHDDMObc8PHZiOaYbjSI8MVPXrl0BuOuuuwDo0qVLg+/3Y/kB3HbbbUC+mUpzexBUTXlt\n0aJFsOy79PkmQ34a6HBX2LW9+uqrwbIf5f/qq68uR2ipU015rSR/tRIeszMOJR3NzNalJgljnHNP\n5lZrutGUU16zSXmtvAYrTqv5r+ohYJ5z7vbQptimkvWjS99///1AvnEzwHbbbdfg+30l4rvW+fte\nkB9XsLmphrzOmDEDyM9X4zsjhPn7nuGrDM/f9xw7dizQuCZMWVMNeU3CgQceGCyPGjWq4scr5VL9\nYOAU4D9m5kd6vZKaBDyRm3p0ETCgyPulOimv2aS8xqCUp+ovA1Zks6YbTSnlNZuU13hUXc+hAw44\nACgcxWb//fcHoGPHjg2+3w/B75uzQH5aDD91sFQHPzqR79Hlx0KF/GhGaxs+fHiwfO+99wKwcOHC\nSoUoVS780CtO6qsuIhJR1VWcxx13XMH3uoRHLnrmmWeA/KRP/gFQJSejl/Ly4wKER2eva6R2EW/S\npEkAnHjiiYkcXxWniEhEFp6SteIHS0GD2gp7wzm3b9JBlJvyqrxmVNG8quIUEYlIJ04RkYh04hQR\niUgnThGRiHTiFBGJSCdOEZGI4m4A/xmwMvc9bTaj6XFvW45AqpDymk3KaxGxtuMEMLNZaWzzlta4\n45LWzyetccclrZ9PpePWpbqISEQ6cYqIRJTEiXNEAscsh7TGHZe0fj5pjTsuaf18Khp37Pc4RUTS\nTpfqIiIR6cQpIhJRbCdOMzvCzN42s4Vmdnlcx43KzLY2s6lmNtfM5pjZhbn17cxsipktyH1vm3Ss\n1SINuVVeo1Ne6zluHPc4zawF8A7QB1gMzAQGOufm1vvGBOTmnO7gnHvTzDYC3gCOBYYAXzjnbs79\nErV1zl2WYKhVIS25VV6jUV7rF1fFuT+w0Dn3nnNuNTAW6B/TsSNxzi1xzr2ZW14BzAM6UhPv6Nxu\no6lJjqQkt8prZMprPZp04oxQyncEPgy9XpxbV9XMrBOwF/A60N45tyS3aSnQPqGwKi7iJVrqcttc\n8wrZ/puNM6+NPnHmSvm7gSOBrsBAM+tarsCSZmatgXHAMOfc8vA2V3N/I5PtuJTXbOYVsp3b2PPq\nnGvUF3AgMDn0+grgivr2zQXfnL8+beznHddXlLyG9k/6c036q+rz2si/2aQ/16S/iua1KaMj1VXK\nH7D2TmY2FBgK7N6EY2XFoqQDKEHUvEo68gol5FZ5LVA0rxV/OOScG+FqRikpPlG6pI7Pq0vhyDlS\nnPJamqacOD8Ctg693iq3rk7OuWebcCyJT6S8Sqoot2XSlBPnTGBHM+tsZusBJwMTyxOWJEh5zS7l\ntkwafY/TObfGzM6j5qFPC2Ckc25O2SKTRCiv2aXclk+soyOZWXwHq05vZPHekfKqvGZU0bxqkA8R\nkYh04hQRiUgnThGRiHTiFBGJKO551aveb3/7WwCuvfbaYN0669T8/9KrVy8AXnzxxdjjEmmuNtpo\no2C5devWABx11FEAbL755gDcfvvtwT6rVq2qeEyqOEVEItKJU0QkIl2q5wwZMgSAyy6rGST6xx9/\nrLVPnG1eRZqrTp06Afm/xQMPPDDYtttuu9X5ng4dOgTLF1xwQeWCy1HFKSISkSrOnG233RaA9ddf\nP+FIpD4HHJAfBW3w4MEAHHLIIQDsuuuutfa/5JJLAPj4448B6NGjR7DtscceA+D111+vTLDSoC5d\nugAwbNiwYN2gQYMAaNWqFQBmFmz78MOaUfFWrFgBwC677ALAgAEDgn3uueceAObPn1+psFVxiohE\n1ewrzt69ewNw/vnnF6wP/2/Vr18/AD755JP4ApMCJ510EgDDhw8P1m222WZAviKZNm1asM03U7nt\nttsKfk64evH7nHzyyeUPWOq08cYbA3DLLbcA+byGmxytbcGCBcHy4YcfDsC6664L5P9O/e/C2suV\noopTRCQinThFRCJq8FLdzEYC/YBlzrndcuvaAY8DnYD3gQHOuS8rF2Z5hR8QPPzww0D+EsILX+It\nWpSWKWVKV+15/clPan419923ZlSvBx54AIANNtgg2Gf69OkAXHfddQC8/PLLwbaWLVsC8MQTTwBw\n2GGH1TrGrFmzyh12Vajm3B53XM0MOr/+9a8b3Pfdd98FoE+fPsE6/3Bohx12qEB0pSul4hwFHLHW\nusuB551zOwLP515LuoxCec2qUSi3FdVgxemcm56b6D2sP9ArtzwamAZcVsa4Kuq0004LlrfccsuC\nbf4BwyOPPBJnSLGr9rz6pkYPPvhgwfopU6YEy/7BwvLlBdNoF2xbu9JcvHhxsDx69OjyBFtlqjm3\nJ554Yp3r33///WB55syZQL4BvK8yw3wzpKQ09ql6e+fcktzyUqB9sR013WiqKK/ZVVJuldfSNLk5\nknPO1TfEvnNuBDACkh+K3zdT+NWvfhWs810rv/rqKwCuv/76+AOrQknk1d+rBLjyyiv9cYB8o2Y/\nehXUXWl6V111VZ3rw93xPv3008YHm2L15bbSf69nnnkmAEOH1pybn3vuOQAWLlwY7LNs2bIGf077\n9kX/T49FY5+qf2JmHQBy3xv+l0oaKK/ZpdyWUWMrzonAacDNue8TyhZRBfhBA8aNG1d0nzvvvBOA\nqVOnxhFStUokr1dffTWQrzIBVq9eDcDkyZOB/P2u7777rtb7fTfZ8P3MbbbZBsg3ePdXEhMmVPWv\naiVVxd+s7/p6zTXXNOnnhAf+SEKDFaeZ/RmYAexsZovN7AxqPvw+ZrYA6J17LSmivGaXclt5pTxV\nH1hk06FljkVipLxml3Jbec2ir/oRR9Q0aevWrVutbc8//zxQ2Ada4rHJJpsAcM455wCF4536S/Rj\njz226Pt9I+gxY8YAsM8++9Ta569//SsAt956axkiljj4B3gbbrhh0X123333gtevvvpqsDxjxozK\nBBaiLpciIhFltuIMVyo331x4OyfcNc83hv/666/jCUwC6623HlD3aDa+6vjpT38KwOmnnw7AMccc\nE+zjRwP3E3iFK1a/7MfcXLlyZVljl6bxXWe7du0KwP/93/8F2/r27Vuwr58sEWrPzOAfNvnfD4Af\nfvihvMHWQRWniEhEmas4S2l69N577wXLGmMzOb7JkW+I7sfHBPjvf/8L1D/Pk682fEP48Lwzn332\nGQBPP/10GSOWxvBjZwLstddeQP7v0+cs3MzM59Xfq/TPKKBwkBfIDwZz/PHHB+v88wr/+1UJqjhF\nRCLSiVNEJKLMXarXN72vt/bDIkmGHx/AP8h75plngm3t2rUD8mMy+h4/o0aNCvb54osvABg7dixQ\neKnu10ly/MO/8KX2k08+WbDPtddeC8ALL7wQrHvllVeA/O9AeNva0wP72zs33XRTsO6DDz4AYPz4\n8QCsWrWqCf+KuqniFBGJKDMV55577gnUPdK356uWt99+O5aYpDR+et7ww6FS9OzZE8hPDxy+ygg/\nAJR4+YdBvpq89NJLa+0zadIkID9GhL/6gPzvwbPPPgsUNnb3D3x8hwZfgfbv3z/Yx3eI+Mc//gHk\nJ4YD+PLLwkHvZ8+eHeFflqeKU0QkosxUnH5cv7Zt29ba9tprrwEwZMiQOEOSCmvVqhWQrzTDTZd0\njzNeLVq0CJb9uKqXXHIJUNj54PLLa2bs8PnxlaafWwrgrrvuAvJNl8LTA5999tlAfhSzNm3aAHDQ\nQQcF+wwaNAjId5YIzxrg+VHlO3fuXPK/MUwVp4hIRJmpODfddFOg7qfpfvTwb775JtaYpLL8QCCS\nPD+iO+QrzW+//RaAs846K9jmrwy7d+8O5LtKHnnkkcE+/kri97//PZCfiRZqzz/kOz/8/e9/D9b5\n5YEDawaJ+uUvf1kr3osuuqjEf1ndShmPc2szm2pmc81sjpldmFvfzsymmNmC3Pfa18hStZTXbFJe\n41HKpfoa4GLnXFegO3CumXVF042mnfKaTcprDKy+vsB1vsFsAnBX7quXc25Jbg6Tac65nRt4b9kn\nf/JlvH/wU9el+nbbbQfAokWLyn34qN5wzu3b8G7xq7a8luLwww8H8s1Wwr/LvjF8TBOyNfu8Llmy\nJFj2zYl8w/P58+cH2/wYm34s1br4aTV8o/Y4RjsqomheI93jzM3VvBfwOppuNDOU12xSXiun5BOn\nmbUGxgHDnHPL/SRYEP90o76xO0Dv3r2BfKXpG8jefffdwT4aAam4asprVP5KQmqLO69Lly4Nln3F\n2bJlSwD22GOPWvv7q4Tp06cD+e6RAO+//z6QaKXZoJKaI5nZutQkYYxzznc21XSjKae8ZpPyWnkN\nVpxW81/VQ8A859ztoU2JTTfq56oB2GKLLQq2ffTRR0C+SYTUrRrzGtVLL70E5EcIr29gl+Yiqbz6\n7q+QH7Rl7733BmDZsvw5euTIkUC+62Mlx8yspFIu1Q8GTgH+Y2a+Y+eV1CTgidzUo4uAAZUJUSpE\nec0m5TUGpUwP/DJgRTZrutGUUl6zSXmNR2Z6Dknz89ZbbwH5vszhh0Xbb789EFtzpGZvxYoVwfKj\njz5a8D2L1FddRCSiVFac4Qa1fiL6Hj16JBWOJOzGG28E4MEHHwzW3XDDDQCcf/75AMydOzf+wCSz\nVHGKiEQUuctlkw6WUEPpKlK1XfOaIum8+jEZn3jiiWCd7xjh57jxo/CEx4YsI+U1m4rmVRWniEhE\nqjjjpcqkgnzlCfl7nH7E8G7dugEVu9epvGaTKk4RkXLRiVNEJCJdqsdLl3TZpLxmky7VRUTKJe4G\n8J8BK3Pf02Yzmh73tuUIpAopr9mkvBYR66U6gJnNSuNlTVrjjktaP5+0xh2XtH4+lY5bl+oiIhHp\nxCkiElESJ84RCRyzHNIad1zS+vmkNe64pPXzqWjcsd/jFBFJO12qi4hEpBOniEhEsZ04zewIM3vb\nzBaa2eVxHTcqM9vazKaa2Vwzm2NmF+bWtzOzKWa2IPe9bdKxVos05FZ5jU55ree4cdzjNLMWwDtA\nH2AxMBMY6JyrumG5c3NOd3DOvWlmGwFvAMcCQ4AvnHM3536J2jrnLksw1KqQltwqr9Eor/WLq+Lc\nH1jonHvPObcaGAv0j+nYkTjnljjn3swtrwDmAR2piXd0brfR1CRHUpJb5TUy5bUeTTpxRijlOwIf\nhl4vzq2rambWCdgLeB1o75xbktu0FGifUFgVF/ESLXW5ba55hWz/zcaZ10afOHOl/N3AkUBXYKCZ\ndS1XYEkzs9bAOGCYc255eJurub+RyXZcyms28wrZzm3seXXONeoLOBCYHHp9BXBFffvmgm/OX582\n9vOO6ytKXkP7J/25Jv1V9Xlt5N9s0p9r0l9F89qU0ZHqKuUPWHsnMxsKDAV2b8KxsmJR0gGUIGpe\nJR15hRJyq7wWKJrXij8ccs6NcDWjlBxX6WNJfHxeXQpHzpHilNfSNOXE+RGwdej1Vrl1dXLOPduE\nY0l8IuVVUkW5LZOmnDhnAjuaWWczWw84GZhYnrAkQcprdim3ZdLoe5zOuTVmdh41D31aACOdc3PK\nFpkkQnnNLuW2fDRZW7w0qVc2Ka/ZpMnaRETKRSdOEZGI4p7lMjbDhw8Pli+44AIA3nrrLQD69esX\nbFu0KC1N8ESkWqjiFBGJKHMVZ6dOnQAYPHhwsO7HH38EYJdddgGgS5cuwTZVnOmw0047AbDuuusG\n63r27AnAPffcA+TzXKoJEyYAcPLJJwOwevXqJscpjRPO60EHHQTAjTfeCMDBBx+cSEz1UcUpIhKR\nTpwiIhFl7lL9008/BWD69OnBumOOOSapcKSRdt11VwCGDBkCwIknngjAOuvk/6/fcsstgfwletQ2\nyf734r777gNg2LBhwbbly5fX+R6pjI033jhYnjp1KgBLly4FYIsttgi2+XVJU8UpIhJR5irOlStX\nAnrok3Y33XQTAH379q34sU499VQAHnrooWDdK6+8UvHjSv18pamKU0QkAzJXcW6yySYA7LHHHglH\nIk0xZcoUoHbFuWzZsmDZV4j+vmddzZF805ZDDjmkInFK5ZhZ0iEUpYpTRCQinThFRCJq8FLdzEYC\n/YBlzrndcuvaAY8DnYD3gQHOuS8rF2bpNthgAwC22Wabovvst99+wfL8+fOB5vcwqdrzeu+99wIw\nfvz4gvX/+9//guVSHhS0adMGyI9T4JswhfljzJo1q3HBVplqz22pfPOy9ddfP+FIaiul4hwFHLHW\nusuB551zOwLP515LuoxCec2qUSi3FdVgxemcm56b6D2sP9ArtzwamAZcVsa4Gu3jjz8GYNSoUcG6\na665pmCf8OuvvvoKgLvuuqvSoVWVas/rmjVrAPjwww8b2LN+hx9+OABt27Ytus/ixYsBWLVqVZOO\nVS2qPbdR7btvfizh1157LcFI8hr7VL29c25Jbnkp0L7YjppuNFWU1+wqKbfKa2ma3BzJOefqG2Lf\nOTcCGAHxDsV/3XXXBctrV5zSsGrNa6n8iEdnnnkmAK1atSq679VXXx1LTNWivtwmlVd/hQHw9ddf\nA/lumNtvv31cYZSssU/VPzGzDgC578sa2F/SQXnNLuW2jBpbcU4ETgNuzn2fULaIKqC+BtJSIFV5\n9QYNGgTA5Zfnn3fssMMOQOE4j2ubPXs2UPikPsOqOrf+WQPASy+9BBTO1FBtGqw4zezPwAxgZzNb\nbGZnUPPh9zGzBUDv3GtJEeU1u5TbyivlqfrAIpsOLXMsEiPlNbuU28rLXF/1ujR2vEZJjp8C5ZRT\nTgGgd+/eRfft0aMHUH9+/fia4cv5Z599FoDvvvuuSbFK86MulyIiETWLilPSYbfddguWJ06cCNTf\ndTYK/8BhxIgRZfl5Ep9NN9006RBqUcUpIhKRKk6pSn4sxlLGZCyluZlv2nLkkUcG6yZNmtSUECUm\n1ThnmCpOEZGIdOIUEYmoWVyq13cp17NnT6D5jY5UjfyYmQC9evUCYPDgwQBMnjwZgO+//76kn3XG\nGWcAcP7555cxQomDnx441T2HRESkkMXZKDypUXR++OEHoP4G0t26dQNg7ty5lQzlDefcvg3vli7V\nODqSH1nn888/L1h/9NFHB8tlfDikvJbRCSecAMBf/vIXoLCDQteuXYHYZmwomldVnCIiETWLe5z3\n3XcfAGeddVbRfYYOrRm7ddiwYbHEJJXlR36X9AmPzQmFTdJatmwZdzh1UsUpIhJRKbNcbg08Qs1Q\n+w4Y4ZwbnqZZ8/xMlpJXDXn1Y2UedthhALzwwgvBtsYMvHH66acHy8OHD29idOlUDXltqgkTaoYK\n9X+3Xbp0Cbb5K8Jzzjkn/sBCSqk41wAXO+e6At2Bc82sK5o1L+2U12xSXmPQ4InTObfEOfdmbnkF\nMA/oSM2seaNzu40Gjq1UkFJ+yms2Ka/xiNQcKTfl6HRgN+AD59wmufUGfOlf1/P+RJutvPPOO0Dd\nkz/5RvJ+yoV33323EiFUZbOVOPPqx84EuOqqqwDo06cPAJ07dw62lTItcLt27QDo27cvAHfeeWew\nbaONNirY11/6h/s9+4bWZdDs81oJf/rTn4DCWzDt29dMzllqR4gmKprXkp+qm1lrYBwwzDm3PPyk\nq75Z8zTdaHVTXrNJea2skn0Ep4kAAAPnSURBVE6cZrYuNUkY45x7Mrf6EzPr4JxbUt+sedU0jeyc\nOXMA2G677Wpta44TuSWR13DX1vD4mwC/+c1vguUVK1Y0+LN8pbr33nv7mGrtM23aNADuvfdeoKxV\nZtXKyt+rF87r6tWrE4wkr5TJ2gx4CJjnnLs9tMnPmgdVOGue1E95zSblNR6lVJwHA6cA/zGz2bl1\nV1IzS94TuRn0FgEDKhNi+fjRv8Pd7pqxqsvr2Wef3aT3L1uWL6KefvppAC688EIgtnti1aDq8tpU\nbdq0CZb79+8PwFNPPZVUOEBps1y+DBQbTVaz5qWU8ppNyms81HNIRCSiZtFX3fMjH82bNy9Yt8su\nuyQVTrM0ZMiQYNmPlXnaaacV2bu2cDOxb7/9Fqh7Irbw2J6STgMG1NxNWLVqVbAu/LebJFWcIiIR\nNauK04/ht/vuuyccSfM1e/bsYNn3N/7nP/8JwPXXXx9sa9u2LQDjx48HYMqUKUC+HzPA0qVLKxus\nJGr69OlA4VVhY8YwqARVnCIiETWLEeCrSFV2zWsq5VV5zSiNAC8iUi46cYqIRKQTp4hIRDpxiohE\npBOniEhEOnGKiEQUdwP4z4CVue9psxlNj3vbcgRShZTXbFJei4i1HSeAmc1KY5u3tMYdl7R+PmmN\nOy5p/XwqHbcu1UVEItKJU0QkoiROnCMa3qUqpTXuuKT180lr3HFJ6+dT0bhjv8cpIpJ2ulQXEYko\nthOnmR1hZm+b2UIzuzyu40ZlZlub2VQzm2tmc8zswtz6dmY2xcwW5L63TTrWapGG3Cqv0Smv9Rw3\njkt1M2sBvAP0ARYDM4GBzrm5FT94RLk5pzs45940s42AN4BjgSHAF865m3O/RG2dc5clGGpVSEtu\nlddolNf6xVVx7g8sdM6955xbDYwF+sd07Eicc0ucc2/mllcA84CO1MQ7OrfbaGqSIynJrfIamfJa\nj7hOnB2BD0OvF+fWVTUz6wTsBbwOtHfOLcltWgq0TyisapO63CqvJVFe66GHQ0WYWWtgHDDMObc8\nvM3V3N9Qc4QUUl6zKe68xnXi/AjYOvR6q9y6qmRm61KThDHOuSdzqz/J3U/x91WWJRVflUlNbpXX\nSJTXesR14pwJ7Ghmnc1sPeBkYGJMx47EzAx4CJjnnLs9tGki4CcAPw2YsPZ7m6lU5FZ5jUx5re+4\ncTWAN7O+wJ+AFsBI59wNsRw4IjPrAbwE/Af4Mbf6SmrumzwBbAMsAgY4575IJMgqk4bcKq/RKa/1\nHFc9h0REotHDIRGRiHTiFBGJSCdOEZGIdOIUEYlIJ04RkYh04hQRiUgnThGRiHTiFBGJ6P8Bgq1N\ntjVszbUAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 9 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPp0Fojs5iu9",
        "colab_type": "text"
      },
      "source": [
        "The dataset already has a well-defined train and test dataset that we can use.\n",
        "\n",
        "In order to estimate the performance of a model for a given training run, we can further split the training set into a train and validation dataset. Performance on the train and validation dataset over each run can then be plotted to provide learning curves and insight into how well a model is learning the problem.\n",
        "\n",
        "The Keras API supports this by specifying the “validation_data” argument to the model.fit() function when training the model, that will, in turn, return an object that describes model performance for the chosen loss and metrics on each training epoch.\n",
        "\n",
        "# record model performance on a validation dataset during training\n",
        "history = model.fit(..., validation_data=(valX, valY))\n",
        "\n",
        "# record model performance on a validation dataset during training\n",
        "history = model.fit(..., validation_data=(valX, valY))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuBhyurO6gDm",
        "colab_type": "text"
      },
      "source": [
        "In order to estimate the performance of a model on the problem in general, we can use k-fold cross-validation, perhaps five-fold cross-validation. This will give some account of the models variance with both respect to differences in the training and test datasets, and in terms of the stochastic nature of the learning algorithm. The performance of a model can be taken as the mean performance across k-folds, given the standard deviation, that could be used to estimate a confidence interval if desired.\n",
        "\n",
        "We can use the KFold class from the scikit-learn API to implement the k-fold cross-validation evaluation of a given neural network model. There are many ways to achieve this, although we can choose a flexible approach where the KFold class is only used to specify the row indexes used for each spit.\n",
        "\n",
        "# example of k-fold cv for a neural net\n",
        "data = ...\n",
        "# prepare cross validation\n",
        "kfold = KFold(5, shuffle=True, random_state=1)\n",
        "# enumerate splits\n",
        "for train_ix, test_ix in kfold.split(data):\n",
        "        model = ...\n",
        "\t...\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dqXwfN7615e",
        "colab_type": "text"
      },
      "source": [
        "**How to Develop a Baseline Model**\n",
        "The first step is to develop a baseline model.\n",
        "\n",
        "This is critical as it both involves developing the infrastructure for the test harness so that any model we design can be evaluated on the dataset, and it establishes a baseline in model performance on the problem, by which all improvements can be compared.\n",
        "\n",
        "The design of the test harness is modular, and we can develop a separate function for each piece. This allows a given aspect of the test harness to be modified or inter-changed, if we desire, separately from the rest.\n",
        "\n",
        "We can develop this test harness with **five key elements**. They are the \n",
        " 1. loading of the dataset, \n",
        " 2. the preparation of the dataset, \n",
        " 3. the definition of the model, \n",
        " 4. the evaluation of the model, \n",
        " 5. the presentation of results. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Noibp9b8ZZS",
        "colab_type": "text"
      },
      "source": [
        "**Load Dataset**\n",
        "We know some things about the dataset.\n",
        "\n",
        "For example, we know that the images are all pre-aligned (e.g. each image only contains a hand-drawn digit), that the images all have the same square size of 28×28 pixels, and that the images are grayscale.\n",
        "\n",
        "Therefore, we can load the images and reshape the data arrays to have a single color channel.\n",
        "\n",
        "# load dataset\n",
        "(trainX, trainY), (testX, testY) = mnist.load_data()\n",
        "\n",
        "# reshape dataset to have a single channel\n",
        "trainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\n",
        "\n",
        "testX = testX.reshape((testX.shape[0], 28, 28, 1))\n",
        "\n",
        "\n",
        "\n",
        "We also know that there are 10 classes and that classes are represented as unique integers.\n",
        "\n",
        "We can, therefore, use a one hot encoding for the class element of each sample, transforming the integer into a 10 element binary vector with a 1 for the index of the class value, and 0 values for all other classes. We can achieve this with the to_categorical() utility function.\n",
        "\n",
        "# one hot encode target values\n",
        "trainY = to_categorical(trainY)\n",
        "\n",
        "testY = to_categorical(testY)\n",
        "\n",
        "The load_dataset() function implements these behaviors and can be used to load the dataset.\n",
        "\n",
        "# load train and test dataset\n",
        "def load_dataset():\n",
        "\t# load dataset\n",
        "\t(trainX, trainY), (testX, testY) = mnist.load_data()\n",
        "\t# reshape dataset to have a single channel\n",
        "\ttrainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\n",
        "\ttestX = testX.reshape((testX.shape[0], 28, 28, 1))\n",
        "\t# one hot encode target values\n",
        "\ttrainY = to_categorical(trainY)\n",
        "\ttestY = to_categorical(testY)\n",
        "\treturn trainX, trainY, testX, testY\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53YOI2q99nUQ",
        "colab_type": "text"
      },
      "source": [
        "**Prepare Pixel Data**\n",
        "We know that the pixel values for each image in the dataset are unsigned integers in the range between black and white, or 0 and 255.\n",
        "\n",
        "We do not know the best way to scale the pixel values for modeling, but we know that some scaling will be required.\n",
        "\n",
        "A good starting point is to normalize the pixel values of grayscale images, e.g. rescale them to the range [0,1]. This involves first converting the data type from unsigned integers to floats, then dividing the pixel values by the maximum value.\n",
        "\n",
        "# convert from integers to floats\n",
        "train_norm = train.astype('float32')\n",
        "\n",
        "test_norm = test.astype('float32')\n",
        "\n",
        "# normalize to range 0-1\n",
        "train_norm = train_norm / 255.0\n",
        "\n",
        "test_norm = test_norm / 255.0\n",
        "\n",
        "The prep_pixels() function below implements these behaviors and is provided with the pixel values for both the train and test datasets that will need to be scaled.\n",
        "\n",
        "# scale pixels\n",
        "def prep_pixels(train, test):\n",
        "\t# convert from integers to floats\n",
        "\ttrain_norm = train.astype('float32')\n",
        "\ttest_norm = test.astype('float32')\n",
        "\t# normalize to range 0-1\n",
        "\ttrain_norm = train_norm / 255.0\n",
        "\ttest_norm = test_norm / 255.0\n",
        "\t# return normalized images\n",
        "\treturn train_norm, test_norm\n",
        "\n",
        "This function must be called to prepare the pixel values prior to any modeling."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfVdhY3V93D3",
        "colab_type": "text"
      },
      "source": [
        "**Define Model**\n",
        "Next, we need to define a baseline convolutional neural network model for the problem.\n",
        "\n",
        "The model has two main aspects: the feature extraction front end comprised of convolutional and pooling layers, and the classifier backend that will make a prediction.\n",
        "\n",
        "For the convolutional front-end, we can start with a single convolutional layer with a small filter size (3,3) and a modest number of filters (32) followed by a max pooling layer. The filter maps can then be flattened to provide features to the classifier.\n",
        "\n",
        "Given that the problem is a multi-class classification task, we know that we will require an output layer with 10 nodes in order to predict the probability distribution of an image belonging to each of the 10 classes. This will also require the use of a softmax activation function. Between the feature extractor and the output layer, we can add a dense layer to interpret the features, in this case with 100 nodes.\n",
        "\n",
        "All layers will use the ReLU activation function and the He weight initialization scheme, both best practices.\n",
        "\n",
        "We will use a conservative configuration for the stochastic gradient descent optimizer with a learning rate of 0.01 and a momentum of 0.9. The categorical cross-entropy loss function will be optimized, suitable for multi-class classification, and we will monitor the classification accuracy metric, which is appropriate given we have the same number of examples in each of the 10 classes.\n",
        "\n",
        "The define_model() function below will define and return this model.\n",
        "\n",
        "# define cnn model\n",
        "def define_model():\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1)))\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.add(Dense(100, activation='relu', kernel_initializer='he_uniform'))\n",
        "\tmodel.add(Dense(10, activation='softmax'))\n",
        "\t# compile model\n",
        "\topt = SGD(lr=0.01, momentum=0.9)\n",
        "\tmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\treturn model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EghhJGNp-KYE",
        "colab_type": "text"
      },
      "source": [
        "**Evaluate Model**\n",
        "After the model is defined, we need to evaluate it.\n",
        "\n",
        "The model will be evaluated using five-fold cross-validation. The value of k=5 was chosen to provide a baseline for both repeated evaluation and to not be so large as to require a long running time. Each test set will be 20% of the training dataset, or about 12,000 examples, close to the size of the actual test set for this problem.\n",
        "\n",
        "The training dataset is shuffled prior to being split, and the sample shuffling is performed each time, so that any model we evaluate will have the same train and test datasets in each fold, providing an apples-to-apples comparison between models.\n",
        "\n",
        "We will train the baseline model for a modest 10 training epochs with a default batch size of 32 examples. The test set for each fold will be used to evaluate the model both during each epoch of the training run, so that we can later create learning curves, and at the end of the run, so that we can estimate the performance of the model. As such, we will keep track of the resulting history from each run, as well as the classification accuracy of the fold.\n",
        "\n",
        "The evaluate_model() function below implements these behaviors, taking the training dataset as arguments and returning a list of accuracy scores and training histories that can be later summarized.\n",
        "\n",
        "# evaluate a model using k-fold cross-validation\n",
        "def evaluate_model(dataX, dataY, n_folds=5):\n",
        "\tscores, histories = list(), list()\n",
        "\t# prepare cross validation\n",
        "\tkfold = KFold(n_folds, shuffle=True, random_state=1)\n",
        "\t# enumerate splits\n",
        "\tfor train_ix, test_ix in kfold.split(dataX):\n",
        "\t\t# define model\n",
        "\t\tmodel = define_model()\n",
        "\t\t# select rows for train and test\n",
        "\t\ttrainX, trainY, testX, testY = dataX[train_ix], dataY[train_ix], dataX[test_ix], dataY[test_ix]\n",
        "\t\t# fit model\n",
        "\t\thistory = model.fit(trainX, trainY, epochs=10, batch_size=32, validation_data=(testX, testY), verbose=0)\n",
        "\t\t# evaluate model\n",
        "\t\t_, acc = model.evaluate(testX, testY, verbose=0)\n",
        "\t\tprint('> %.3f' % (acc * 100.0))\n",
        "\t\t# stores scores\n",
        "\t\tscores.append(acc)\n",
        "\t\thistories.append(history)\n",
        "\treturn scores, histories\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4IH3CPkS--yL",
        "colab_type": "text"
      },
      "source": [
        "**Present Results**\n",
        "Once the model has been evaluated, we can present the results.\n",
        "\n",
        "There are two key aspects to present: the diagnostics of the learning behavior of the model during training and the estimation of the model performance. These can be implemented using separate functions.\n",
        "\n",
        "First, the diagnostics involve creating a line plot showing model performance on the train and test set during each fold of the k-fold cross-validation. These plots are valuable for getting an idea of whether a model is overfitting, underfitting, or has a good fit for the dataset.\n",
        "\n",
        "We will create a single figure with two subplots, one for loss and one for accuracy. Blue lines will indicate model performance on the training dataset and orange lines will indicate performance on the hold out test dataset. The summarize_diagnostics() function below creates and shows this plot given the collected training histories.\n",
        "\n",
        "# plot diagnostic learning curves\n",
        "def summarize_diagnostics(histories):\n",
        "\tfor i in range(len(histories)):\n",
        "\t\t# plot loss\n",
        "\t\tpyplot.subplot(2, 1, 1)\n",
        "\t\tpyplot.title('Cross Entropy Loss')\n",
        "\t\tpyplot.plot(histories[i].history['loss'], color='blue', label='train')\n",
        "\t\tpyplot.plot(histories[i].history['val_loss'], color='orange', label='test')\n",
        "\t\t# plot accuracy\n",
        "\t\tpyplot.subplot(2, 1, 2)\n",
        "\t\tpyplot.title('Classification Accuracy')\n",
        "\t\tpyplot.plot(histories[i].history['accuracy'], color='blue', label='train')\n",
        "\t\tpyplot.plot(histories[i].history['val_accuracy'], color='orange', label='test')\n",
        "\tpyplot.show()\n",
        "\n",
        "Next, the classification accuracy scores collected during each fold can be summarized by calculating the mean and standard deviation. This provides an estimate of the average expected performance of the model trained on this dataset, with an estimate of the average variance in the mean. We will also summarize the distribution of scores by creating and showing a box and whisker plot.\n",
        "\n",
        "The summarize_performance() function below implements this for a given list of scores collected during model evaluation.\n",
        "\n",
        "# summarize model performance\n",
        "def summarize_performance(scores):\n",
        "\t# print summary\n",
        "\tprint('Accuracy: mean=%.3f std=%.3f, n=%d' % (mean(scores)*100, std(scores)*100, len(scores)))\n",
        "\t# box and whisker plots of results\n",
        "\tpyplot.boxplot(scores)\n",
        "\tpyplot.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UclsOhZd_9Km",
        "colab_type": "text"
      },
      "source": [
        "**Complete Example**\n",
        "We need a function that will drive the test harness.\n",
        "\n",
        "This involves calling all of the define functions.\n",
        "\n",
        "# run the test harness for evaluating a model\n",
        "def run_test_harness():\n",
        "\t# load dataset\n",
        "\ttrainX, trainY, testX, testY = load_dataset()\n",
        "\t# prepare pixel data\n",
        "\ttrainX, testX = prep_pixels(trainX, testX)\n",
        "\t# evaluate model\n",
        "\tscores, histories = evaluate_model(trainX, trainY)\n",
        "\t# learning curves\n",
        "\tsummarize_diagnostics(histories)\n",
        "\t# summarize estimated performance\n",
        "\tsummarize_performance(scores)\n",
        "\n",
        "We now have everything we need; the complete code example for a baseline convolutional neural network model on the MNIST dataset is listed below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7us4Ci_sAI4x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 787
        },
        "outputId": "0029a17e-ccbc-42c6-cfdb-c2ff24f8afd8"
      },
      "source": [
        "\n",
        "# baseline cnn model for mnist\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from matplotlib import pyplot\n",
        "from sklearn.model_selection import KFold\n",
        "from keras.datasets import mnist\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.optimizers import SGD\n",
        " \n",
        "# load train and test dataset\n",
        "def load_dataset():\n",
        "\t# load dataset\n",
        "\t(trainX, trainY), (testX, testY) = mnist.load_data()\n",
        "\t# reshape dataset to have a single channel\n",
        "\ttrainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\n",
        "\ttestX = testX.reshape((testX.shape[0], 28, 28, 1))\n",
        "\t# one hot encode target values\n",
        "\ttrainY = to_categorical(trainY)\n",
        "\ttestY = to_categorical(testY)\n",
        "\treturn trainX, trainY, testX, testY\n",
        " \n",
        "# scale pixels\n",
        "def prep_pixels(train, test):\n",
        "\t# convert from integers to floats\n",
        "\ttrain_norm = train.astype('float32')\n",
        "\ttest_norm = test.astype('float32')\n",
        "\t# normalize to range 0-1\n",
        "\ttrain_norm = train_norm / 255.0\n",
        "\ttest_norm = test_norm / 255.0\n",
        "\t# return normalized images\n",
        "\treturn train_norm, test_norm\n",
        " \n",
        "# define cnn model\n",
        "def define_model():\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1)))\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.add(Dense(100, activation='relu', kernel_initializer='he_uniform'))\n",
        "\tmodel.add(Dense(10, activation='softmax'))\n",
        "\t# compile model\n",
        "\topt = SGD(lr=0.01, momentum=0.9)\n",
        "\tmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\treturn model\n",
        " \n",
        "# evaluate a model using k-fold cross-validation\n",
        "def evaluate_model(dataX, dataY, n_folds=5):\n",
        "\tscores, histories = list(), list()\n",
        "\t# prepare cross validation\n",
        "\tkfold = KFold(n_folds, shuffle=True, random_state=1)\n",
        "\t# enumerate splits\n",
        "\tfor train_ix, test_ix in kfold.split(dataX):\n",
        "\t\t# define model\n",
        "\t\tmodel = define_model()\n",
        "\t\t# select rows for train and test\n",
        "\t\ttrainX, trainY, testX, testY = dataX[train_ix], dataY[train_ix], dataX[test_ix], dataY[test_ix]\n",
        "\t\t# fit model\n",
        "\t\thistory = model.fit(trainX, trainY, epochs=10, batch_size=32, validation_data=(testX, testY), verbose=0)\n",
        "\t\t# evaluate model\n",
        "\t\t_, acc = model.evaluate(testX, testY, verbose=0)\n",
        "\t\tprint('> %.3f' % (acc * 100.0))\n",
        "\t\t# stores scores\n",
        "\t\tscores.append(acc)\n",
        "\t\thistories.append(history)\n",
        "\treturn scores, histories\n",
        " \n",
        "# plot diagnostic learning curves\n",
        "def summarize_diagnostics(histories):\n",
        "\tfor i in range(len(histories)):\n",
        "\t\t# plot loss\n",
        "\t\tpyplot.subplot(2, 1, 1)\n",
        "\t\tpyplot.title('Cross Entropy Loss')\n",
        "\t\tpyplot.plot(histories[i].history['loss'], color='blue', label='train')\n",
        "\t\tpyplot.plot(histories[i].history['val_loss'], color='orange', label='test')\n",
        "\t\t# plot accuracy\n",
        "\t\tpyplot.subplot(2, 1, 2)\n",
        "\t\tpyplot.title('Classification Accuracy')\n",
        "\t\tpyplot.plot(histories[i].history['acc'], color='blue', label='train')\n",
        "\t\tpyplot.plot(histories[i].history['val_acc'], color='orange', label='test')\n",
        "\tpyplot.show()\n",
        " \n",
        "# summarize model performance\n",
        "def summarize_performance(scores):\n",
        "\t# print summary\n",
        "\tprint('Accuracy: mean=%.3f std=%.3f, n=%d' % (mean(scores)*100, std(scores)*100, len(scores)))\n",
        "\t# box and whisker plots of results\n",
        "\tpyplot.boxplot(scores)\n",
        "\tpyplot.show()\n",
        " \n",
        "# run the test harness for evaluating a model\n",
        "def run_test_harness():\n",
        "\t# load dataset\n",
        "\ttrainX, trainY, testX, testY = load_dataset()\n",
        "\t# prepare pixel data\n",
        "\ttrainX, testX = prep_pixels(trainX, testX)\n",
        "\t# evaluate model\n",
        "\tscores, histories = evaluate_model(trainX, trainY)\n",
        "\t# learning curves\n",
        "\tsummarize_diagnostics(histories)\n",
        "\t# summarize estimated performance\n",
        "\tsummarize_performance(scores)\n",
        " \n",
        "# entry point, run the test harness\n",
        "run_test_harness()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "> 98.467\n",
            "> 98.692\n",
            "> 98.642\n",
            "> 98.875\n",
            "> 98.608\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:75: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:80: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:75: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:80: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:75: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:80: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:75: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:80: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy: mean=98.657 std=0.132, n=5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD4CAYAAAAHHSreAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAZN0lEQVR4nO3df4xV52Hm8e+zw2CklKQOTCzXYxkr\nOLszmlI7ubbkHwhMNpIdVWbBUQUbRXFL4lVliLSVpRqNqqZkvWyQo6S2rEokposjFdtB2V2IaqMs\nDOui4ohLbcBkSkqsxmZgydjYUVDkGMizf5wX9nrOJHMZrhlDno90xDnvj3PeN3LmmfecuffINhER\nEa3+zVQPICIi3n8SDhERUZNwiIiImoRDRETUJBwiIqJm2lQPoBNmz57tOXPmTPUwIiIuKXv37n3d\nds94dZdFOMyZM4dmsznVw4iIuKRI+smvq8ttpYiIqEk4RERETcIhIiJqEg4REVGTcIiIiJqEQ8R7\nYNOmTQwMDNDV1cXAwACbNm2a6iFFnJfL4k9ZI95PNm3axODgIE888QR33HEHu3btYsWKFQAsX758\nikcX0R5dDl/Z3Wg0nM85xPvFwMAAjz32GHfeeee5sqGhIVatWsXLL788hSOLeDdJe203xq1LOER0\nVldXF2+//Tbd3d3nyk6dOsWMGTM4c+bMFI4s4t1+UzjkmUNEh/X19bFr1653le3atYu+vr4pGlHE\n+Us4RHTY4OAgK1asYGhoiFOnTjE0NMSKFSsYHByc6qFFtC0PpCM67OxD51WrVjE8PExfXx8PP/xw\nHkbHJSXPHCIifkvlmUNERJyXhENERNQkHCIioibhEBERNW2Fg6S7JB2SdFjSQ+PUXydpu6T9knZK\n6m2pWyfpoKRhSY9KUilfLulA6fOcpNml/MuSRiS9VLZPd2qyERHRngnDQVIX8DhwN9APLJfUP6bZ\nI8CTtucBa4C1pe9twO3APGAAuBlYIGka8NfAnaXPfmBly/m+bvvGsv39hUwwIiLOXzsrh1uAw7Zf\nsf0O8BSweEybfmBH2R9qqTcwA5gOXAF0A8cBle0DZSXxQeDoBcwjIiI6qJ1wuAZ4reX4SClrtQ9Y\nWvaXADMlzbK9myosjpVtm+1h26eAPwUOUIVCP/BEy/lWlttNGyRdOd6gJN0vqSmpOTo62sY0IiKi\nXZ16IP0g1e2iF4EFwAhwRtJcoA/opQqURZLmS+qmCoebgN+juq20upzrb4CPAjdSBcrXxrug7fW2\nG7YbPT09HZpGRERAe1+fMQJc23LcW8rOsX2UsnKQ9DvAvbbfkvRF4AXbJ0vds8CtwNul349L+TPA\nQ6Xs+NnzSvom8L1JzSwiIiatnZXDHuAGSddLmg4sA7a0NpA0W9LZc60GNpT9VykPoMtqYQEwTBUu\n/ZLO/sr/qVKOpKtbTr0EyBfgR0RcZBOuHGyflrQS2AZ0ARtsH5S0Bmja3gIsBNZKMvA88EDpvhlY\nRPVswcBztrcCSPor4HlJp4CfAPeVPusk3Vja/yvwnzowz4iIOA/54r2IiN9S+eK9iIg4LwmHiIio\nSThERERNwiEiImoSDhERUZNwiIiImoRDRETUJBwiIqIm4RARETUJh4iIqEk4RERETcIhIiJqEg4R\nEVGTcIiIiJqEQ0RE1LQVDpLuknRI0mFJD41Tf52k7ZL2S9opqbelbp2kg5KGJT0qSaV8uaQDpc9z\nkmaX8g9L+r6kfyn/XtmpyUZERHsmDAdJXcDjwN1AP7BcUv+YZo8AT9qeB6wB1pa+twG3A/OAAeBm\nymtDgb8G7ix99gMry7keArbbvgHYXo4jIuIiamflcAtw2PYrtt8BngIWj2nTD+wo+0Mt9QZmANOB\nK4Bu4Digsn2grCQ+CBwtfRYDG8v+RuA/nOecIiLiArUTDtcAr7UcHyllrfYBS8v+EmCmpFm2d1OF\nxbGybbM9bPsU8KdU75Y+ShUuT5T+V9k+Vvb/L3DV+U0pIiIuVKceSD9IdbvoRWABMAKckTQX6AN6\nqQJlkaT5krqpwuEm4PeobiutHntSVy+4Hvcl15Lul9SU1BwdHe3QNCIiAtoLhxHg2pbj3lJ2ju2j\ntpfavgkYLGVvUa0iXrB90vZJ4FngVuDG0ubHJQCeAW4rpzsu6WqA8u9PxxuU7fW2G7YbPT097c02\nIiLa0k447AFukHS9pOnAMmBLawNJsyWdPddqYEPZf5XyALqsFhYAw1Th0i/p7E/1T5Vyyrk/X/Y/\nD/yv859WRERciAnDwfZpqr8k2kb1A/wZ2wclrZF0T2m2EDgk6UdUzwgeLuWbgR9TPVvYB+yzvdX2\nUeCvgOcl7adaSfzX0ue/AZ+S9C/Avy/HERFxEam6q3NpazQabjabUz2MiIhLiqS9thvj1eUT0hER\nUZNwiIiImoRDRETUJBwiIqIm4RARETUJh4iIqEk4RERETcIhIiJqEg4REVGTcIiIiJqEQ0RE1CQc\nIiKiJuEQERE1CYeIiKhJOERERE3CISIiatoKB0l3STok6bCkh8apv07Sdkn7Je2U1NtSt07SQUnD\nkh5VZaakl1q21yV9o7S/T9JoS90XOjfdiIhox7SJGkjqAh6nes/zEWCPpC22f9jS7BHgSdsbJS0C\n1gKfk3QbcDswr7TbBSywvZPq1aBnr7EX+G7L+Z62vXLy04qIiAvRzsrhFuCw7VdsvwM8BSwe06Yf\n2FH2h1rqDcwApgNXAN3A8daOkj4GfAT4h8lMICIiOq+dcLgGeK3l+Egpa7UPWFr2lwAzJc2yvZsq\nLI6VbZvt4TF9l1GtFFpfZn1vuUW1WdK14w1K0v2SmpKao6OjbUwjIiLa1akH0g8CCyS9CCwARoAz\nkuYCfUAvVaAskjR/TN9lwKaW463AHNvzgO8DG8e7oO31thu2Gz09PR2aRkREQHvhMAK0/vbeW8rO\nsX3U9lLbNwGDpewtqlXEC7ZP2j4JPAvcerafpD8Aptne23KuN2z/shx+C/jE+U8rIiIuRDvhsAe4\nQdL1kqZT/aa/pbWBpNmSzp5rNbCh7L9KtaKYJqmbalXReltpOe9eNSDp6pbDe8a0j4iIi2DCv1ay\nfVrSSmAb0AVssH1Q0hqgaXsLsBBYK8nA88ADpftmYBFwgOrh9HO2t7ac/o+AT4+55Jck3QOcBk4A\n901ybhERMUl693PgS1Oj0XCz2ZzqYUREXFIk7bXdGK8un5COiIiahENERNQkHCIioibhEBERNQmH\niIioSThERERNwiEiImoSDhERUZNwiIiImoRDRETUJBwiIqIm4RARETUJh4iIqEk4RERETcIhIiJq\n2goHSXdJOiTpsKSHxqm/TtJ2Sfsl7ZTU21K3TtJBScOSHlVlpqSXWrbXJX2jtL9C0tPlWj+QNKdT\nk42IiPZMGA6SuoDHgbuBfmC5pP4xzR4BnrQ9D1gDrC19bwNuB+YBA8DNwALbP7d949kN+Anw3XKu\nFcCbtucCXwe+eoFzjIiI89TOyuEW4LDtV2y/AzwFLB7Tph/YUfaHWuoNzACmA1cA3cDx1o6SPgZ8\nBPiHUrQY2Fj2NwOflKR2JxQREReunXC4Bnit5fhIKWu1D1ha9pcAMyXNsr2bKiyOlW2b7eExfZcB\nT/v/v6/03PVsnwZ+BswaOyhJ90tqSmqOjo62MY2IiGhXpx5IPwgskPQisAAYAc5Imgv0Ab1UP/QX\nSZo/pu8yYNP5XtD2etsN242enp4LG31ERLxLO+EwAlzbctxbys6xfdT2Uts3AYOl7C2qVcQLtk/a\nPgk8C9x6tp+kPwCm2d473vUkTQM+BLxxvhOLiIjJaycc9gA3SLpe0nSq3/S3tDaQNFvS2XOtBjaU\n/VepVhTTJHVTrSpabystp75q2AJ8vux/BtjRcsspIiIugmkTNbB9WtJKYBvQBWywfVDSGqBpewuw\nEFgrycDzwAOl+2ZgEXCA6uH0c7a3tpz+j4BPj7nkE8C3JR0GTlCFUUTHffjDH+bNN9+c6mF0xJVX\nXsmJEyemehhxGdHl8Et5o9Fws9mc6mHEJUYSl8N//3B5zSUuHkl7bTfGq8snpCMioibhEBERNQmH\niIioSThERERNwiEiImoSDhERUZNwiIiImoRDRETUJBwiIqIm4RARETUJh4iIqEk4RERETcIhIiJq\nEg4REVGTcIiIiJq2wkHSXZIOSTos6aFx6q+TtF3Sfkk7JfW21K2TdFDSsKRHJamUT5e0XtKPJP2z\npHtL+X2SRiW9VLYvdGqyERHRngnfBCepC3gc+BRwBNgjaYvtH7Y0ewR40vZGSYuAtcDnJN0G3A7M\nK+12Ub0qdCfVu6Z/avtj5RWjH24539O2V17Y1CIiYrImDAfgFuCw7VcAJD0FLAZaw6Ef+LOyPwT8\nz7JvYAYwHRDQDRwvdX8C/DsA278CXp/0LCIioqPaua10DfBay/GRUtZqH7C07C8BZkqaZXs3VVgc\nK9s228OSfre0/Yqkf5L0HUlXtZzv3nKLarOka8cblKT7JTUlNUdHR9uYRkREtKtTD6QfBBZIepHq\nttEIcEbSXKAP6KUKlEWS5lOtWHqBf7T9cWA31a0pgK3AHNvzgO8DG8e7oO31thu2Gz09PR2aRkRE\nQHvhMAK0/vbeW8rOsX3U9lLbN1E9S8D2W1SriBdsn7R9EngWuBV4A/gF8N1yiu8AHy/93rD9y1L+\nLeATk5lYRERMXjvhsAe4QdL1kqYDy4AtrQ0kzS4PlQFWAxvK/qtUK4ppkrqpVhXDtk21QlhY2n2S\n8gxD0tUtp74HGD7vWUVExAWZ8IG07dOSVgLbgC5gg+2DktYATdtbqH7Ir5Vk4HnggdJ9M7AIOED1\ncPo521tL3Z8D35b0DWAU+ONS/iVJ9wCngRPAfRc8y4hx+C8/CF/+0FQPoyP8lx+c6iHEZUbVL/GX\ntkaj4WazOdXDiEuMJC6H//7h8ppLXDyS9tpujFeXT0hHRERNwiEiImoSDhERUZNwiIiImoRDRETU\nJBwiIqIm4RARETUJh4iIqEk4RERETcIhIiJqEg4REVGTcIiIiJqEQ0RE1CQcIiKiZsL3OURcziRN\n9RA64sorr5zqIcRlpq2Vg6S7JB2SdFjSQ+PUXydpu6T9knZK6m2pWyfpoKRhSY+q/L9R0nRJ6yX9\nSNI/S7q3lF8h6elyrR9ImtOZqUa8m+3LZjtx4sRU/88Zl5kJw0FSF/A4cDfQDyyX1D+m2SPAk7bn\nAWuAtaXvbcDtwDxgALiZ6lWhUL1r+qe2P1bO+39K+QrgTdtzga8DX5307CIiYlLaWTncAhy2/Yrt\nd4CngMVj2vQDO8r+UEu9gRnAdOAKoBs4Xur+hBIitn9l+/VSvhjYWPY3A5/U5bL2j4i4RLQTDtcA\nr7UcHyllrfYBS8v+EmCmpFm2d1OFxbGybbM9LOl3S9uvSPonSd+RdNXY69k+DfwMmDV2UJLul9SU\n1BwdHW1jGhER0a5O/bXSg8ACSS9S3TYaAc5Imgv0Ab1UP/QXSZpP9SC8F/hH2x8HdlPdmmqb7fW2\nG7YbPT09HZpGRERAe+EwAlzbctxbys6xfdT2Uts3UT1LwPZbVKuIF2yftH0SeBa4FXgD+AXw3XKK\n7wAfH3s9SdOAD5X2ERFxkbQTDnuAGyRdL2k6sAzY0tpA0mxJZ8+1GthQ9l+lWlFMk9RNtaoYtm1g\nK7CwtPsk8MOyvwX4fNn/DLCjtI+IiItkws852D4taSWwDegCNtg+KGkN0LS9heqH/FpJBp4HHijd\nNwOLgANUD6efs7211P058G1J3wBGgT8u5U+U8sPACaowioiIi0iXwy/ljUbDzWZzqocREXFJkbTX\ndmO8unx9RkRE1CQcIiKiJuEQERE1CYeIiKhJOERERE3CISIiahIOERFRk3CIiIiahENERNQkHCIi\noibhEBERNQmHiIioSThERERNwiEiImoSDhERUdNWOEi6S9IhSYclPTRO/XWStkvaL2mnpN6WunWS\nDkoalvSoJJXyneWcL5XtI6X8PkmjLeVf6NRkIyKiPRO+CU5SF/A48CngCLBH0hbbP2xp9gjwpO2N\nkhYBa4HPSboNuB2YV9rtonpV6M5y/Fnb472l52nbKyczoYiIuHDtrBxuAQ7bfsX2O8BTwOIxbfqB\nHWV/qKXewAxgOnAF0A0cv9BBR0TEe6udcLgGeK3l+Egpa7UPWFr2lwAzJc2yvZsqLI6VbZvt4ZZ+\nf1tuHf3F2dtNxb3lFtVmSdeez4QiIuLCdeqB9IPAAkkvUt02GgHOSJoL9AG9VIGySNL80ueztn8f\nmF+2z5XyrcAc2/OA7wMbx7ugpPslNSU1R0dHOzSNiIiA9sJhBGj97b23lJ1j+6jtpbZvAgZL2VtU\nq4gXbJ+0fRJ4Fri11I+Uf38O/B3V7Stsv2H7l+XU3wI+Md6gbK+33bDd6OnpaWuyERHRnnbCYQ9w\ng6TrJU0HlgFbWhtImi3p7LlWAxvK/qtUK4ppkrqpVhXD5Xh26dsN/CHwcjm+uuXU9wCtt6EiIuIi\nmPCvlWyflrQS2AZ0ARtsH5S0Bmja3gIsBNZKMvA88EDpvhlYBBygejj9nO2tkj4AbCvB0AX8b+Cb\npc+XJN0DnAZOAPd1ZKYREdE22Z7qMVywRqPhZnO8v4iNiIhfR9Je243x6vIJ6YiIqEk4RERETcIh\nIiJqEg4REVGTcIiIiJqEQ0RE1CQcIiKiJuEQERE1CYeIiKhJOERERE3CISIiahIOERFRk3CIiIia\nhENERNQkHCIioibhEBERNW2Fg6S7JB2SdFjSQ+PUXydpu6T9knZK6m2pWyfpoKRhSY9KUinfWc75\nUtk+UsqvkPR0udYPJM3pzFQjIqJdE4aDpC7gceBuoB9YLql/TLNHgCdtzwPWAGtL39uA24F5wABw\nM9V7pM/6rO0by/bTUrYCeNP2XODrwFcnO7mIiJicdlYOtwCHbb9i+x3gKWDxmDb9wI6yP9RSb2AG\nMB24AugGjk9wvcXAxrK/Gfjk2dVGRERcHO2EwzXAay3HR0pZq33A0rK/BJgpaZbt3VRhcaxs22wP\nt/T723JL6S9aAuDc9WyfBn4GzBo7KEn3S2pKao6OjrYxjYiIaFenHkg/CCyQ9CLVbaMR4IykuUAf\n0Ev1Q3+RpPmlz2dt/z4wv2yfO58L2l5vu2G70dPT06FpREQEtBcOI8C1Lce9pewc20dtL7V9EzBY\nyt6iWkW8YPuk7ZPAs8CtpX6k/Ptz4O+obl+963qSpgEfAt6Y1OwiImJS2gmHPcANkq6XNB1YBmxp\nbSBptqSz51oNbCj7r1KtKKZJ6qZaVQyX49mlbzfwh8DLpc8W4PNl/zPADtue3PQiImIyJgyHct9/\nJbANGAaesX1Q0hpJ95RmC4FDkn4EXAU8XMo3Az8GDlA9l9hneyvVw+ltkvYDL1GtFr5Z+jwBzJJ0\nGPgzoPansxER8d7S5fBLeaPRcLPZnOphRERcUiTttd0Yry6fkI6IiJqEQ0RE1CQcIiKiJuEQERE1\nCYeIiKhJOERERE3CISIiahIOEe+BTZs2MTAwQFdXFwMDA2zatGmqhxRxXqZN9QAiLjebNm1icHCQ\nJ554gjvuuINdu3axYsUKAJYvXz7Fo4toTz4hHdFhAwMDPPbYY9x5553nyoaGhli1ahUvv/zyb+gZ\ncXH9pk9IJxwiOqyrq4u3336b7u7uc2WnTp1ixowZnDlzZgpHFvFu+fqMiIuor6+PXbt2vats165d\n9PX1TdGIIs5fwiGiwwYHB1mxYgVDQ0OcOnWKoaEhVqxYweDg4FQPLaJteSAd0WFnHzqvWrWK4eFh\n+vr6ePjhh/MwOi4peeYQEfFb6oKfOUi6S9IhSYcl1V6+I+k6Sdsl7Ze0U1JvS906SQclDUt6VJLG\n9N0i6eWW4y9LGpH0Utk+3f5UIyKiEyYMB0ldwOPA3UA/sFxS/5hmjwBP2p4HrAHWlr63AbcD84AB\n4GaqV4WePfdS4OQ4l/267RvL9vfnPauIiLgg7awcbgEO237F9jvAU8DiMW36gR1lf6il3sAMYDrV\nq0G7geMAkn6H6jWg/+VCJhAREZ3XTjhcA7zWcnyklLXaBywt+0uAmZJm2d5NFRbHyrbN9nBp9xXg\na8AvxrnmynKLaoOkK8cblKT7JTUlNUdHR9uYRkREtKtTf8r6ILBA0otUt41GgDOS5gJ9QC9VoCyS\nNF/SjcBHbf+Pcc71N8BHgRupAuVr413Q9nrbDduNnp6eDk0jIiKgvT9lHQGubTnuLWXn2D5KWTmU\n20X32n5L0heBF2yfLHXPArcCPwcakv61jOEjknbaXmj7+NnzSvom8L2JBrh3797XJf2kjblEXGyz\ngdenehARv8Z1v66inXDYA9wg6XqqUFgG/MfWBpJmAyds/wpYDWwoVa8CX5S0FhDVquIbtrdSrRCQ\nNAf4nu2F5fhq28dK/yXAhF9GYztLh3hfktT8dX8qGPF+NuFtJdungZXANmAYeMb2QUlrJN1Tmi0E\nDkn6EXAV8HAp3wz8GDhA9VxiXwmG32SdpAOS9gN3Av/5POcUEREX6LL4EFzE+1VWDnGpyncrRby3\n1k/1ACImIyuHiIioycohIiJqEg4REVGTcIh4D5RP9/+09UslIy4lCYeI98Z/B+6a6kFETFbCIeI9\nYPt54MRUjyNishIOERFRk3CIiIiahENERNQkHCIioibhEPEekLQJ2A38W0lHJK2Y6jFFnI98fUZE\nRNRk5RARETUJh4iIqEk4RERETcIhIiJqEg4REVGTcIiIiJqEQ0RE1Pw/375Af0VjE1gAAAAASUVO\nRK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ma-pLx8jGLYg",
        "colab_type": "text"
      },
      "source": [
        "Save Final Model\n",
        "A final model is typically fit on all available data, such as the combination of all train and test dataset.\n",
        "\n",
        "In this tutorial, we are intentionally holding back a test dataset so that we can estimate the performance of the final model, which can be a good idea in practice. As such, we will fit our model on the training dataset only.\n",
        "\n",
        "# fit model\n",
        "model.fit(trainX, trainY, epochs=10, batch_size=32, verbose=0)\n",
        "\n",
        "Once fit, we can save the final model to an H5 file by calling the save() function on the model and pass in the chosen filename.\n",
        "\n",
        "# save model\n",
        "model.save('final_model.h5')\n",
        "\n",
        "Note, saving and loading a Keras model requires that the h5py library is installed on your workstation.\n",
        "\n",
        "The complete example of fitting the final deep model on the training dataset and saving it to file is listed below.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDK182f7GgH-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# save the final model to file\n",
        "from keras.datasets import mnist\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "# load train and test dataset\n",
        "def load_dataset():\n",
        "\t# load dataset\n",
        "\t(trainX, trainY), (testX, testY) = mnist.load_data()\n",
        "\t# reshape dataset to have a single channel\n",
        "\ttrainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\n",
        "\ttestX = testX.reshape((testX.shape[0], 28, 28, 1))\n",
        "\t# one hot encode target values\n",
        "\ttrainY = to_categorical(trainY)\n",
        "\ttestY = to_categorical(testY)\n",
        "\treturn trainX, trainY, testX, testY\n",
        "\n",
        "# scale pixels\n",
        "def prep_pixels(train, test):\n",
        "\t# convert from integers to floats\n",
        "\ttrain_norm = train.astype('float32')\n",
        "\ttest_norm = test.astype('float32')\n",
        "\t# normalize to range 0-1\n",
        "\ttrain_norm = train_norm / 255.0\n",
        "\ttest_norm = test_norm / 255.0\n",
        "\t# return normalized images\n",
        "\treturn train_norm, test_norm\n",
        "\n",
        "# define cnn model\n",
        "def define_model():\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1)))\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform'))\n",
        "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform'))\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.add(Dense(100, activation='relu', kernel_initializer='he_uniform'))\n",
        "\tmodel.add(Dense(10, activation='softmax'))\n",
        "\t# compile model\n",
        "\topt = SGD(lr=0.01, momentum=0.9)\n",
        "\tmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\treturn model\n",
        "\n",
        "# run the test harness for evaluating a model\n",
        "def run_test_harness():\n",
        "\t# load dataset\n",
        "\ttrainX, trainY, testX, testY = load_dataset()\n",
        "\t# prepare pixel data\n",
        "\ttrainX, testX = prep_pixels(trainX, testX)\n",
        "\t# define model\n",
        "\tmodel = define_model()\n",
        "\t# fit model\n",
        "\tmodel.fit(trainX, trainY, epochs=10, batch_size=32, verbose=0)\n",
        "\t# save model\n",
        "\tmodel.save('final_model.h5')\n",
        "\n",
        "# entry point, run the test harness\n",
        "run_test_harness()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5COMj97CHdAW",
        "colab_type": "text"
      },
      "source": [
        "**Evaluate Final Model**\n",
        "We can now load the final model and evaluate it on the hold out test dataset.\n",
        "\n",
        "This is something we might do if we were interested in presenting the performance of the chosen model to project stakeholders.\n",
        "\n",
        "The model can be loaded via the load_model() function.\n",
        "\n",
        "The complete example of loading the saved model and evaluating it on the test dataset is listed below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVuICLOBHm70",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "79f30a3d-71f3-49eb-c786-ae79b2b39484"
      },
      "source": [
        "\n",
        "# evaluate the deep model on the test dataset\n",
        "from keras.datasets import mnist\n",
        "from keras.models import load_model\n",
        "from keras.utils import to_categorical\n",
        " \n",
        "# load train and test dataset\n",
        "def load_dataset():\n",
        "\t# load dataset\n",
        "\t(trainX, trainY), (testX, testY) = mnist.load_data()\n",
        "\t# reshape dataset to have a single channel\n",
        "\ttrainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\n",
        "\ttestX = testX.reshape((testX.shape[0], 28, 28, 1))\n",
        "\t# one hot encode target values\n",
        "\ttrainY = to_categorical(trainY)\n",
        "\ttestY = to_categorical(testY)\n",
        "\treturn trainX, trainY, testX, testY\n",
        " \n",
        "# scale pixels\n",
        "def prep_pixels(train, test):\n",
        "\t# convert from integers to floats\n",
        "\ttrain_norm = train.astype('float32')\n",
        "\ttest_norm = test.astype('float32')\n",
        "\t# normalize to range 0-1\n",
        "\ttrain_norm = train_norm / 255.0\n",
        "\ttest_norm = test_norm / 255.0\n",
        "\t# return normalized images\n",
        "\treturn train_norm, test_norm\n",
        " \n",
        "# run the test harness for evaluating a model\n",
        "def run_test_harness():\n",
        "\t# load dataset\n",
        "\ttrainX, trainY, testX, testY = load_dataset()\n",
        "\t# prepare pixel data\n",
        "\ttrainX, testX = prep_pixels(trainX, testX)\n",
        "\t# load model\n",
        "\tmodel = load_model('final_model.h5')\n",
        "\t# evaluate model on test dataset\n",
        "\t_, acc = model.evaluate(testX, testY, verbose=0)\n",
        "\tprint('> %.3f' % (acc * 100.0))\n",
        " \n",
        "# entry point, run the test harness\n",
        "run_test_harness()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "> 99.180\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbkXajOpIRax",
        "colab_type": "text"
      },
      "source": [
        "**Make Prediction**\n",
        "We can use our saved model to make a prediction on new images.\n",
        "\n",
        "The model assumes that new images are grayscale, that they have been aligned so that one image contains one centered handwritten digit, and that the size of the image is square with the size 28×28 pixels.\n",
        "We will pretend this is an entirely new and unseen image, prepared in the required way, and see how we might use our saved model to predict the integer that the image represents (e.g. we expect “7“).\n",
        "\n",
        "First, we can load the image, force it to be in grayscale format, and force the size to be 28×28 pixels. The loaded image can then be resized to have a single channel and represent a single sample in a dataset. The load_image() function implements this and will return the loaded image ready for classification.\n",
        "\n",
        "Importantly, the pixel values are prepared in the same way as the pixel values were prepared for the training dataset when fitting the final model, in this case, normalized."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Klej4tEpLxH8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkGhTt5LIYAr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b35a9c4f-ce3d-4436-fc32-350e2a87636a"
      },
      "source": [
        "\n",
        "# make a prediction for a new image.\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.models import load_model\n",
        " \n",
        "# load and prepare the image\n",
        "def load_image(filename):\n",
        "\t# load the image\n",
        "\timg = load_img(filename, color_mode = \"grayscale\", target_size=(28, 28))\n",
        "\t# convert to array\n",
        "\timg = img_to_array(img)\n",
        "\t# reshape into a single sample with 1 channel\n",
        "\timg = img.reshape(1, 28, 28, 1)\n",
        "\t# prepare pixel data\n",
        "\timg = img.astype('float32')\n",
        "\timg = img / 255.0\n",
        "\treturn img\n",
        " \n",
        "# load an image and predict the class\n",
        "def run_example():\n",
        "\t# load the image\n",
        "\timg = load_image('sample_image.png')\n",
        "\t# load model\n",
        "\tmodel = load_model('final_model.h5')\n",
        "\t# predict the class\n",
        "\tdigit = model.predict_classes(img)\n",
        "\tprint(digit[0])\n",
        " \n",
        "# entry point, run the example\n",
        "run_example()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
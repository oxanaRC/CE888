{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab9_exercise2_GAN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM3U7xStGloVTsKOG5vTUZl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oxanaRC/CE888/blob/master/Lab9/Lab9_exercise2_GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqDcU9bJTG_B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras import layers\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9nce_dwTZuL",
        "colab_type": "text"
      },
      "source": [
        "**GAN Generator Network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzsrTaz-Tb4h",
        "colab_type": "code",
        "outputId": "c4c27e6b-1ab8-49e6-c43b-ace51a94e30d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        }
      },
      "source": [
        "latent_dim = 32\n",
        "height = 32\n",
        "width = 32\n",
        "channels = 3\n",
        "\n",
        "generator_input = keras.Input(shape=(latent_dim,))\n",
        "\n",
        "# Transforms the input into a 16 × 16 128-channel feature map\n",
        "x = layers.Dense(128 * 16 * 16)(generator_input)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Reshape((16, 16, 128))(x)\n",
        "\n",
        "x = layers.Conv2D(256, 5, padding='same')(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "\n",
        "# Upsamples to 32 × 32\n",
        "x = layers.Conv2DTranspose(256, 4, strides=2, padding='same')(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "\n",
        "x = layers.Conv2D(256, 5, padding='same')(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Conv2D(256, 5, padding='same')(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "\n",
        "# Produces a 32 × 32 1-channel feature map (shape of a CIFAR10 image)\n",
        "x = layers.Conv2D(channels, 7, activation='tanh', padding='same')(x)\n",
        "\n",
        "# Instantiates the generator model, which maps the input of shape (latent_dim,) \n",
        "#into an image of shape (32, 32, 3)\n",
        "generator = keras.models.Model(generator_input, x)\n",
        "generator.summary()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_5 (InputLayer)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 32768)             1081344   \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_10 (LeakyReLU)   (None, 32768)             0         \n",
            "_________________________________________________________________\n",
            "reshape_2 (Reshape)          (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 16, 16, 256)       819456    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_11 (LeakyReLU)   (None, 16, 16, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_2 (Conv2DTr (None, 32, 32, 256)       1048832   \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_12 (LeakyReLU)   (None, 32, 32, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 32, 32, 256)       1638656   \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_13 (LeakyReLU)   (None, 32, 32, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 32, 32, 256)       1638656   \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_14 (LeakyReLU)   (None, 32, 32, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 32, 32, 3)         37635     \n",
            "=================================================================\n",
            "Total params: 6,264,579\n",
            "Trainable params: 6,264,579\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWswmZZfTm-h",
        "colab_type": "text"
      },
      "source": [
        "**GAN Discriminator Network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgFrZqkoTqZI",
        "colab_type": "code",
        "outputId": "cd30ecdb-88a8-4a7a-960f-4ace2c614093",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        }
      },
      "source": [
        "discriminator_input = layers.Input(shape=(height, width, channels))\n",
        "\n",
        "x = layers.Conv2D(128, 3)(discriminator_input)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Conv2D(128, 4, strides=2)(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Conv2D(128, 4, strides=2)(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Conv2D(128, 4, strides=2)(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Flatten()(x)\n",
        "\n",
        "# One dropout layer: an important trick\n",
        "x = layers.Dropout(0.4)(x)\n",
        "\n",
        "# Classification layer\n",
        "x = layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "#Instantiates the discriminator model, which turns a (32, 32, 3) input into a binary \n",
        "#classification decision (fake/real)\n",
        "discriminator = keras.models.Model(discriminator_input, x)\n",
        "discriminator.summary()\n",
        "\n",
        "# Uses gradient clipping (by value) in the optimizer and To stabilize training, \n",
        "# uses learning-rate decay\n",
        "discriminator_optimizer = keras.optimizers.RMSprop(lr=0.0008,clipvalue=1.0,decay=1e-8)\n",
        "discriminator.compile(optimizer=discriminator_optimizer,loss='binary_crossentropy')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_6 (InputLayer)         (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 30, 30, 128)       3584      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_15 (LeakyReLU)   (None, 30, 30, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 14, 14, 128)       262272    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_16 (LeakyReLU)   (None, 14, 14, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_15 (Conv2D)           (None, 6, 6, 128)         262272    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_17 (LeakyReLU)   (None, 6, 6, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_16 (Conv2D)           (None, 2, 2, 128)         262272    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_18 (LeakyReLU)   (None, 2, 2, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 790,913\n",
            "Trainable params: 790,913\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3Ol3BqXWMqu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Sets discriminator weights to non-trainable (this will only apply to the gan model)\n",
        "discriminator.trainable = False\n",
        "\n",
        "gan_input = keras.Input(shape=(latent_dim,))\n",
        "gan_output = discriminator(generator(gan_input))\n",
        "gan = keras.models.Model(gan_input, gan_output)\n",
        "\n",
        "gan_optimizer = keras.optimizers.RMSprop(lr=0.0004, clipvalue=1.0, decay=1e-8)\n",
        "gan.compile(optimizer=gan_optimizer, loss='binary_crossentropy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLiAWk05Vu-h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "outputId": "0a75efaf-b9cb-4c85-9ac7-2738953dafe1"
      },
      "source": [
        "import os\n",
        "from keras.preprocessing import image\n",
        "os.mkdir('GAN')\n",
        "\n",
        "# Loads CIFAR10 data\n",
        "(x_train, y_train), (_, _) = keras.datasets.cifar10.load_data()\n",
        "\n",
        "# Selects frog images (class 6)\n",
        "x_train = x_train[y_train.flatten() == 6]\n",
        "\n",
        "x_train = x_train.reshape(\n",
        "    (x_train.shape[0],) +\n",
        "    (height, width, channels)).astype('float32') / 255.\n",
        "\n",
        "iterations = 10000\n",
        "batch_size = 20\n",
        "save_dir = '/content/GAN'# Specifies where you want to save generated images\n",
        "\n",
        "start = 0\n",
        "# Samples random points in the latent space\n",
        "for step in range(iterations):\n",
        "    random_latent_vectors = np.random.normal(size=(batch_size, latent_dim))\n",
        "\n",
        "# Decodes them to fake images    \n",
        "generated_images = generator.predict(random_latent_vectors)\n",
        "\n",
        "# Combines them with real images \n",
        "stop = start + batch_size\n",
        "real_images = x_train[start: stop]\n",
        "combined_images = np.concatenate([generated_images, real_images])\n",
        "\n",
        "labels = np.concatenate([np.ones((batch_size, 1)), np.zeros((batch_size, 1))])\n",
        "labels += 0.05 * np.random.random(labels.shape)\n",
        "\n",
        "# Trains the discriminator\n",
        "d_loss = discriminator.train_on_batch(combined_images, labels)\n",
        "\n",
        "# Samples random points in the latent space\n",
        "random_latent_vectors = np.random.normal(size=(batch_size,latent_dim))\n",
        "\n",
        "# Assembles latent space labels that say “these are all real images” (it’s a lie!)\n",
        "misleading_targets = np.zeros((batch_size, 1))\n",
        "\n",
        "# Trains the generator (via the gan model, where the discriminator weights are frozen)\n",
        "a_loss = gan.train_on_batch(random_latent_vectors, misleading_targets)\n",
        "\n",
        "start += batch_size\n",
        "if start > len(x_train) - batch_size: \n",
        "    start = 0\n",
        "    \n",
        "if step % 100 == 0: \n",
        "    gan.save_weights('gan.h5')\n",
        "    \n",
        "print('discriminator loss:', d_loss)\n",
        "print('adversarial loss:', a_loss)\n",
        "\n",
        "img = image.array_to_img(generated_images[0] * 255., scale=False)\n",
        "img.save(os.path.join(save_dir,\n",
        "                      'generated_frog' + str(step) + '.png'))\n",
        "\n",
        "img = image.array_to_img(real_images[0] * 255., scale=False)\n",
        "img.save(os.path.join(save_dir,\n",
        "                      'real_frog' + str(step) + '.png'))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-228474e35f03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Loads CIFAR10 data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcifar10\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Selects frog images (class 6)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'keras' is not defined"
          ]
        }
      ]
    }
  ]
}